{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "day2_torch_nn&dataloader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jieunjeon/ml-implementation-pytorch/blob/main/pytorch_tutorial/day2_torch_nn%26dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21TlCc95rF-L"
      },
      "source": [
        "# ì´ì›ƒì§‘ í† í† ì¹˜Â íŒŒì´í† ì¹˜ : Day 2\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIOz112trF-W"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <p>ğŸ“¢ í•´ë‹¹ ê²Œì‹œë¬¼ì€ íŒŒì´í† ì¹˜ ê³µì‹ íŠœí† ë¦¬ì–¼ ì¤‘ <a href=\"https://tutorials.pytorch.kr/beginner/nn_tutorial.htmlhttps://tutorials.pytorch.kr/beginner/nn_tutorial.html\">TORCH.NN ì´ ì‹¤ì œë¡œ ë¬´ì—‡ì¸ê°€ìš”?</a>ì™€ <a href=\"https://tutorials.pytorch.kr/beginner/basics/intro.htmlhttps://tutorials.pytorch.kr/beginner/basics/intro.html\">íŒŒì´í† ì¹˜ ê¸°ë³¸ ìµíˆê¸°</a>ë¥¼ ì¬êµ¬ì„±í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNUHTULsrF-Y"
      },
      "source": [
        "#### ì£¼ìš” í‚¤ì›Œë“œ\n",
        "- ì‹ ê²½ë§ ì„¤ê³„ - nn.Module, sequence\n",
        "- train loop\n",
        "- optimization\n",
        "- loss\n",
        "- dataset, dataloader\n",
        "- cnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDBVxQy5rF-Z"
      },
      "source": [
        "#### ëª©ì°¨\n",
        "1. Tensorë¥¼ ì‚¬ìš©í•œ ì‹ ê²½ë§\n",
        "    1. ë°ì´í„° ì¤€ë¹„\n",
        "    2. ì‹ ê²½ë§ ì •ì˜\n",
        "    3. training loop ì •ì˜\n",
        "2. torch.nn.functional ì‚¬ìš©í•˜ê¸°\n",
        "    1. torch.nn.functional ì‚¬ìš©í•˜ê¸°\n",
        "    2. nn.Module ì„ ì´ìš©í•˜ì—¬ ë¦¬íŒ©í† ë§ í•˜ê¸°\n",
        "    3. nn.Linear ë¥¼ ì´ìš©í•˜ì—¬ ë¦¬íŒ©í† ë§ í•˜ê¸°\n",
        "3. optmì„ ì´ìš©í•˜ì—¬ ë¦¬íŒ©í† ë§ í•˜ê¸°\n",
        "4. fit() ì™€ get_data() ìƒì„±í•˜ê¸°\n",
        "5. CNN ìœ¼ë¡œ ë„˜ì–´ê°€ê¸°\n",
        "    1. nn.Module\n",
        "    2. nn.Sequential\n",
        "    3. DataLoader ê°ì‹¸ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfpFvs6krF-a"
      },
      "source": [
        "#### ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vshB8VkurF-b",
        "tags": []
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda\") # GPUì—ì„œ ì‹¤í–‰í•˜ë ¤ë©´ ì´ ì£¼ì„ì„ ì œê±°í•˜ì„¸ìš”"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6rfl8gyrF-e"
      },
      "source": [
        "## 1. Tensorë¥¼ ì‚¬ìš©í•œ ì‹ ê²½ë§\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLUOEMGarF-f"
      },
      "source": [
        "Day1ì—ì„œëŠ” Tensorì™€ autogradë¥¼ ì´ìš©í•˜ì—¬ ì‹ ê²½ë§ì„ êµ¬ì„±í•˜ëŠ” ë²•ì„ ìµí˜”ìŠµë‹ˆë‹¤. í•´ë‹¹ ë¶€ë¶„ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ì˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì‹ ê²½ë§ì„ êµ¬ì¶•í•˜ì—¬ ë´…ì‹œë‹¤.\n",
        "\n",
        "- FashionMNIST ë¶„ë¥˜ê¸°(ì…ë ¥: 784, ì¶œë ¥: 10)\n",
        "- ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì„ ê°€ì§€ëŠ” ì„ í˜•ëª¨ë¸\n",
        "- í™œì„±í™” í•¨ìˆ˜ : log softmax\n",
        "- ì†ì‹¤ í•¨ìˆ˜ : negative log-likelihood)\n",
        "- í‰ê°€ ì§€í‘œ : accuracy\n",
        "- training loopì—ì„œëŠ” ì•„ë˜ì˜ ë™ì‘ì„ ìˆ˜í–‰\n",
        "    - ë°ì´í„°ì—ì„œ ë°°ì¹˜(64)ë¥¼ ì„ íƒ ğŸ‘‰ DataLoader ì‚¬ìš©\n",
        "    - ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "    - ì†ì‹¤ ê³„ì‚°\n",
        "    - `backward()`ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì˜ ê¸°ìš¸ê¸° ì—…ë°ì´íŠ¸ ğŸ‘‰ weight, bias ì—…ë°ì´íŠ¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We3qysP6rF-h"
      },
      "source": [
        "### A. ë°ì´í„° ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUl9orNkrF-i"
      },
      "source": [
        "Day1ì—ì„œ ì‚¬ìš©ë˜ì—ˆë˜ [FashionMNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist) ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ì¤€ë¹„í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‹¤ìŠµì„ ìœ„í•˜ì—¬ ì´ì „ì—ëŠ” `TorchVison`ì—ì„œ ë¶ˆëŸ¬ì™”ë˜ ê²ƒê³¼ ë‹¬ë¦¬, ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œ ë°›ì€ í›„ ì´ë¥¼ ì§ì ‘ ì •ì˜í•œ `CustomDataset`ìœ¼ë¡œ ì½ì–´ë“¤ì´ê³ ì í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mhYAz3grF-j"
      },
      "source": [
        "#### a. ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
        "ë°ì´í„°ë¥¼ í˜„ì¬ ì‘ì—…í™˜ê²½ ì•„ë˜ì˜ `data`í´ë”ì— ë‹¤ìš´ë¡œë“œ ë°›ìŠµë‹ˆë‹¤. ì´ë•Œ, `wget` íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ëŠ”ë° ë§Œì•½ í˜„ì¬ ê°€ìƒí™˜ê²½ì— ì„¤ì¹˜ ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´ ì•„ë˜ì˜ pip ì½”ë“œë¥¼ ìˆ˜í–‰ì‹œì¼œ ì„¤ì¹˜ë¥¼ ì§„í–‰ í•©ë‹ˆë‹¤.\n",
        "\n",
        "FashionMNIST ë°ì´í„°ì…‹ì€ 60000ê°œì˜ í•™ìŠµìš© ë°ì´í„°ì™€ 100000ê°œì˜ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¡œ êµ¬ë¶„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•™ìŠµìš© ë°ì´í„° ì¤‘ 10%(6000ê°œ)ë¥¼ validation setìœ¼ë¡œ ë¶„ë¦¬í•˜ë„ë¡ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQXS8x6FrF-j"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMAOPTcjrYVH"
      },
      "source": [
        "!mkdir ./data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCb2KH2urF-k",
        "tags": []
      },
      "source": [
        "import wget\n",
        "\n",
        "urls = ['http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
        "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
        "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
        "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz']\n",
        "\n",
        "for url in urls:\n",
        "    # data í´ë” í•˜ìœ„ì— urlì— ê²Œì¬ë˜ì–´ ìˆëŠ” ìë£Œë¥¼ ë‹¤ìš´ë„ë¥´ ë°›ëŠ”ë‹¤ \n",
        "    wget.download(url, './data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfMY4VD_rF-l",
        "tags": []
      },
      "source": [
        "# code source : https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
        "# gz íŒŒì¼ì„ ì—´ì–´ ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ ì½ì–´ë“¤ì—¬ ë°˜í™˜í•´ì¤€ë‹¤.\n",
        "def load_mnist(path, kind='train'):\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "        labels = labels.astype(np.int64)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images/255.0, labels\n",
        "\n",
        "\n",
        "x_train, y_train = load_mnist('data', kind='train')\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)\n",
        "x_test, y_test = load_mnist('data', kind='t10k')\n",
        "\n",
        "\n",
        "print(f'train : image{x_train.shape}/{type(x_train[0])}, label{y_train.shape}/{type(y_train[0])}')\n",
        "print(f'valid : image{x_val.shape}/{type(x_val[0])}, label{y_val.shape}/{type(y_val[0])}')\n",
        "print(f'test  : image{x_test.shape}/{type(x_test[0])}, label{y_test.shape}/{type(y_test[0])}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9aAN7MTrF-q"
      },
      "source": [
        "í•™ìŠµ ë°ì´í„°ì…‹ 60000ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ 10000ì´ ì •ìƒì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_u9hP7RrF-q"
      },
      "source": [
        "#### b. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹/ë°ì´í„°ë¡œë” ì •ì˜\n",
        "ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì—ì„œëŠ” `__init__`, `__len__`, `__getitem__`ì„ ì •ì˜í•´ì•¼ í•˜ë©´ ê° ë©”ì„œë“œì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "- `__init__` : í´ë˜ìŠ¤ì˜ ë©¤ë²„ë³€ìˆ˜ x, y, transform, target_transformì„ íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•˜ì—¬ ì´ˆê¸°í™” í•©ë‹ˆë‹¤. ì´ë•Œ, xëŠ” image ë°ì´í„°/yëŠ” ë¼ë²¨/transformì€ ì´ë¯¸ì§€ì— ì ìš© ë  transform/target_transformì€ ë¼ë²¨ì— ì ìš© ë  transformì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "- `__len__` : ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "- `__getitem__` : ì£¼ì–´ì§„ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ (image, label) ìŒìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ë•Œ, imageì—ëŠ” transformì„ ì ìš©í•˜ê³  ë¼ë²¨ì—ëŠ” target_transformì„ ì ìš©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHgBu5KBrF-r",
        "tags": []
      },
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, x, y, transform=None, target_transform=None):\n",
        "        self.labels = [\"T-Shirt\",  \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
        "                       \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "        \n",
        "        self.x = x # ì´ë¯¸ì§€\n",
        "        self.y = y # ë¼ë²¨\n",
        "        self.transform = transform # ì´ë¯¸ì§€ì— ì ìš© ë  transform\n",
        "        self.target_transform = target_transform # ë¼ë²¨ì— ì ìš© ë  transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y) # ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ê°œìˆ˜\n",
        "\n",
        "    def __getitem__(self, idx): # ì£¼ì–´ì§„ idxë²ˆì§¸ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ ë°˜í™˜\n",
        "        img = self.x[idx]\n",
        "        label = self.y[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(img)\n",
        "        \n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqAWy6ojrF-s"
      },
      "source": [
        "training loopì—ì„œëŠ” ë°°ì¹˜ë¥¼ ì„ íƒí•˜ëŠ” êµ¬ê°„ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ë¥¼ ìˆ˜ì›”í•˜ê¸° ì§„í–‰í•˜ê¸° ìœ„í•˜ì—¬ ìœ„ì—ì„œ `DataLoader`ë¥¼ ì´ìš©í•˜ë ¤ê³  í•©ë‹ˆë‹¤. DataLoaderê°€ ì–´ë–¤ ê¸°ëŠ¥ì„ í•˜ëŠ”ì§€ ê°€ë¬¼ê°€ë¬¼ í•˜ì‹œë‹¤ë©´ ì•„ë˜ì˜ ì„¤ëª…ì„ í™•ì¸í•´ ë³´ì„¸ìš”.\n",
        "\n",
        "<details>\n",
        "    <summary>DataLoader</summary>\n",
        "    <div markdown=\"1\">       \n",
        "      `DataLoader` ì— ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¨ ë’¤ì—ëŠ” í•„ìš”ì— ë”°ë¼ ë°ì´í„°ì…‹ì„ ìˆœíšŒ(iterate)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì˜ ê° ìˆœíšŒ(iteration)ëŠ” (ê°ê° `batch_size=64` ì˜ íŠ¹ì§•(feature)ê³¼ ì •ë‹µ(label)ì„ í¬í•¨í•˜ëŠ”) `train_features` ì™€ `train_labels` ì˜ ë¬¶ìŒ(batch)ì„ ë°˜í™˜í•©ë‹ˆë‹¤. `shuffle=True` ë¡œ ì§€ì •í–ˆìœ¼ë¯€ë¡œ, ëª¨ë“  ë°°ì¹˜ë¥¼ ìˆœíšŒí•œ ë’¤ ë°ì´í„°ê°€ ì„ì…ë‹ˆë‹¤.\n",
        "(ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ìˆœì„œë¥¼ ë³´ë‹¤ ì„¸ë°€í•˜ê²Œ(finer-grained) ì œì–´í•˜ë ¤ë©´ <a href=\"https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler\" >Samplers</a>\n",
        "ë¥¼ ì‚´í´ë³´ì„¸ìš”.)\n",
        "    </div>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOdVvzd5rF-s",
        "tags": []
      },
      "source": [
        "train_ds = CustomImageDataset(x_train, y_train, \n",
        "                              transform=torch.Tensor)\n",
        "val_ds = CustomImageDataset(x_val, y_val, \n",
        "                            transform=torch.Tensor)\n",
        "\n",
        "x_test = torch.Tensor(x_test).to(device)\n",
        "y_test = torch.from_numpy(y_test).to(device)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=64, shuffle=True)\n",
        "\n",
        "train_dl, val_dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTplQVgXrF-t"
      },
      "source": [
        "ë°ì´í„° ë¡œë”ê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ ë°°ì¹˜ í•˜ë‚˜ë¥¼ ì¶œë ¥í•˜ì—¬ í™•ì¸í•´ ë´…ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVYbwTRGrF-t",
        "tags": []
      },
      "source": [
        "def get_label_name(label): # ë¼ë²¨(ìˆ«ì)ë¥¼ ì…ë ¥ë°›ì•„ í•´ë‹¹ ë¼ë²¨ì˜ ì˜ë¯¸ë¥¼ ë°˜í™˜\n",
        "    LABLE_NAMES = [\"T-Shirt\",  \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
        "                   \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "    return LABLE_NAMES[label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbswZ-hQrF-u",
        "tags": []
      },
      "source": [
        "def show_batch(features, labels):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for i in range(1, 65):\n",
        "        img = features[i-1]\n",
        "        label = get_label_name(labels[i-1])\n",
        "        ax = fig.add_subplot(8, 8, i)\n",
        "        \n",
        "        \n",
        "        if device.type  == \"cuda\":\n",
        "            img = img.cpu()\n",
        "        ax.imshow(img.reshape(28,28), cmap=\"gray\")\n",
        "        ax.set_title(label)\n",
        "        ax.set_xticks([]), ax.set_yticks([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv38MmXzrF-u",
        "tags": []
      },
      "source": [
        "features, labels = next(iter(train_dl))\n",
        "features, labels = features.to(device), labels.to(device)\n",
        "show_batch(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xYQCQXCrF-v"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. `get_label_name(np.argmax(labels[i-1]))`ëŠ” ì¸ì½”ë”© ë˜ì–´ ìˆëŠ” ë¼ë²¨ê°’ì„ ë¼ë²¨ì˜ ì´ë¦„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ argmax í•¨ìˆ˜ê°€ í•˜ëŠ” ì—­í• ì„ ë¬´ì—‡ì¸ê°€ìš”?</b></p>\n",
        "    <p>ğŸ‘‰ (ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•´ ì£¼ì„¸ìš”)</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Vtu4d7rF-v"
      },
      "source": [
        "### B. ì‹ ê²½ë§ ì •ì˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkG8xlFKrF-v"
      },
      "source": [
        "#### a. ê°€ì¤‘ì¹˜ ì •ì˜\n",
        "\n",
        "PyTorchëŠ” ëœë¤ ë˜ëŠ” 0ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ í…ì„œë¥¼ ìƒì„±í•˜ëŠ” ë©”ì„œë“œë¥¼ ì œê³µí•˜ê³ , ìš°ë¦¬ëŠ” ê°„ë‹¨í•œ ì„ í˜• ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜(weights)ì™€ ì ˆí¸(bias)ì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œ ì´ê²ƒì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ì´ë“¤ì€ ì¼ë°˜ì ì¸ í…ì„œì— ë§¤ìš° íŠ¹ë³„í•œ í•œ ê°€ì§€ê°€ ì¶”ê°€ëœ ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "ìš°ë¦¬ëŠ” PyTorchì—ê²Œ ì´ë“¤ì´ ê¸°ìš¸ê¸°(gradient)ê°€ í•„ìš”í•˜ë‹¤ê³  ì•Œë ¤ì¤ë‹ˆë‹¤.\n",
        "ì´ë¥¼ í†µí•´ PyTorchëŠ” í…ì„œì— í–‰í•´ì§€ëŠ” ëª¨ë“  ì—°ì‚°ì„ ê¸°ë¡í•˜ê²Œ í•˜ê³ ,\n",
        "ë”°ë¼ì„œ *ìë™ì ìœ¼ë¡œ* ì—­ì „íŒŒ(back-propagation) ë™ì•ˆì— ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
        "\n",
        "ê°€ì¤‘ì¹˜ì— ëŒ€í•´ì„œëŠ” `requires_grad_` ë¥¼ ì´ˆê¸°í™”(initialization) **ë‹¤ìŒì—** ì„¤ì •í•©ë‹ˆë‹¤,\n",
        "ì™œëƒí•˜ë©´ ìš°ë¦¬ëŠ” í•´ë‹¹ ë‹¨ê³„ê°€ ê¸°ìš¸ê¸°ì— í¬í•¨ë˜ëŠ” ê²ƒì„ ì›ì¹˜ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
        "(PyTorchì—ì„œ `_` ë‹¤ìŒì— ì˜¤ëŠ” ë©”ì„œë“œ ì´ë¦„ì€ ì—°ì‚°ì´ ì¸í”Œë ˆì´ìŠ¤(in-place)ë¡œ ìˆ˜í–‰ë˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.)\n",
        "\n",
        "<div class=\"alert alert-info\"><b>ğŸ“Œ Note</b><p><a href=\"http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\"><u>Xavier initialisation</u></a> \n",
        "   ê¸°ë²•ì„ ì´ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™” í•©ë‹ˆë‹¤. Standard gaussianì„ ì´ìš©í•´ ìƒì„±í•œ ë‚œìˆ˜ë¥¼ 'ì…ë ¥ì˜ ìˆ˜'ë¡œ ë‚˜ëˆ„ì–´ ìŠ¤ì¼€ì¼ë§ í•©ë‹ˆë‹¤. ì´ì— ëŒ€í•´ì„œëŠ” cs231n lec6ì—ì„œ ë‹¤ë¤„ì§€ê³  ìˆìœ¼ë‹ˆ í•œë²ˆ ì‚´í´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.</p></div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcg8KkzprF-v",
        "tags": []
      },
      "source": [
        "weights = torch.randn(784, 10, device=device) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, device=device, requires_grad=True)\n",
        "weights, bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqjbx7H1rF-w"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. ìœ„ì—ì„œ ì •ì˜í•œ ê°€ì¤‘ì¹˜ì˜ í˜•ìƒì€ (784x10) ì…ë‹ˆë‹¤. ì™œ ì´ë ‡ê²Œ ì •ì˜ë˜ì—ˆì„ê¹Œìš”?</b></p>\n",
        "    <p>ğŸ‘‰ (ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•´ ì£¼ì„¸ìš”)</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AqREKsdrF-w"
      },
      "source": [
        "#### b. ëª¨ë¸ ì •ì˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJtuCVTJrF-w"
      },
      "source": [
        "PyTorchì˜ ê¸°ìš¸ê¸°ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì£¼ëŠ” ê¸°ëŠ¥ ë•ë¶„ì—, Python í‘œì¤€ í•¨ìˆ˜\n",
        "(ë˜ëŠ” í˜¸ì¶œ ê°€ëŠ¥í•œ ê°ì²´)ë¥¼ ëª¨ë¸ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
        "ê·¸ëŸ¬ë¯€ë¡œ ê°„ë‹¨í•œ ì„ í˜• ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œ ë‹¨ìˆœí•œ í–‰ë ¬ ê³±ì…ˆê³¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸(broadcast) ë§ì…ˆì„ ì‚¬ìš©í•˜ì—¬ ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë˜í•œ, ìš°ë¦¬ëŠ” í™œì„±í™” í•¨ìˆ˜(activation function)ê°€ í•„ìš”í•˜ë¯€ë¡œ,`log_softmax` ë¥¼ êµ¬í˜„í•˜ê³  ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. PyTorchì—ì„œ ë§ì€ ì‚¬ì „ êµ¬í˜„ëœ ì†ì‹¤ í•¨ìˆ˜(loss function), í™œì„±í™” í•¨ìˆ˜ë“¤ì´ ì œê³µë˜ì§€ë§Œ, ì¼ë°˜ì ì¸ pythonì„ ì‚¬ìš©í•˜ì—¬ ìì‹ ë§Œì˜ í•¨ìˆ˜ë¥¼ ì‰½ê²Œ ì‘ì„±í•  ìˆ˜ ìˆìŒì„ ê¸°ì–µí•´ì£¼ì„¸ìš”.\n",
        "\n",
        "PyTorchëŠ” ì‹¬ì§€ì–´ ì—¬ëŸ¬ë¶„ì˜ í•¨ìˆ˜ë¥¼ ìœ„í•´ì„œ ë¹ ë¥¸ GPU ë˜ëŠ” ë²¡í„°í™”ëœ CPU ì½”ë“œë¥¼ ë§Œë“¤ì–´ì¤„ ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkDVaK-krF-w",
        "tags": []
      },
      "source": [
        "def log_softmax(x):\n",
        "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb):\n",
        "    return log_softmax(xb @ weights + bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcQSbzpFrF-w"
      },
      "source": [
        "<details>\n",
        "    <summary>log_softmaxì˜ ì •ì˜ê°€ ì™œ ì €ë ‡ê²Œ ë˜ì§€?-í•˜ëŠ” ì˜ë¬¸ì— ìƒê¸´ë‹¤ë©´ ì•„ë˜ì˜ ë§í¬ë“¤ì„ í™•ì¸í•´ ë³´ì„¸ìš”.</summary>\n",
        "    <div markdown=\"1\">       \n",
        "        â€¢ <a href=\"https://forums.fast.ai/t/what-is-torch-nn-really/36206/6\">What is torch.nn really?</a><br>\n",
        "        â€¢ <a href=\"https://discuss.pytorch.org/t/log-softmax-function-in-pytorch-tutorial-example/52041\">â€œlog_softmax functionâ€ in pytorch tutorial example</a>\n",
        "    </div>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K959uBDJrF-x"
      },
      "source": [
        "ìœ„ì—ì„œ, `@` ê¸°í˜¸ëŠ” ì ê³±(dot product) ì—°ì‚°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
        "ìš°ë¦¬ëŠ” í•˜ë‚˜ì˜ ë°°ì¹˜(batch) ë°ì´í„°(ì´ ê²½ìš°ì—ëŠ” 64ê°œì˜ ì´ë¯¸ì§€ë“¤)ì— ëŒ€í•˜ì—¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ê²ƒì…ë‹ˆë‹¤.\n",
        "ì´ê²ƒì€ í•˜ë‚˜ì˜ *í¬ì›Œë“œ ì „ë‹¬(forward pass)* ì…ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œ ìš°ë¦¬ëŠ” ë¬´ì‘ìœ„(random) ê°€ì¤‘ì¹˜ë¡œ\n",
        "ì‹œì‘í–ˆê¸° ë•Œë¬¸ì— ìš°ë¦¬ì˜ ì˜ˆì¸¡ì´ ë¬´ì‘ìœ„ ì˜ˆì¸¡ë³´ë‹¤ ì „í˜€ ë‚˜ì€ ì ì´ ì—†ì„ ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODSs5E02rF-x",
        "tags": []
      },
      "source": [
        "preds = model(features)  # ì˜ˆì¸¡\n",
        "print(f'preds[0] : {preds[0]}\\npreds.shape : {preds.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNLIjx5QrF-x",
        "tags": []
      },
      "source": [
        "preds_label = torch.argmax(preds, -1)\n",
        "show_batch(features, preds_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgxgWAWFrF-y"
      },
      "source": [
        "#### c. loss\n",
        "\n",
        "ì—¬ëŸ¬ë¶„ì´ ë³´ì‹œë“¯ì´, ``preds`` í…ì„œ(tensor)ëŠ” í…ì„œ ê°’ ì™¸ì—ë„, ë˜í•œ\n",
        "ê¸°ìš¸ê¸° í•¨ìˆ˜(gradient function)ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "ìš°ë¦¬ëŠ” ë‚˜ì¤‘ì— ì´ê²ƒì„ ì—­ì „íŒŒ(backpropagation)ë¥¼ ìœ„í•´ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n",
        "ì´ì œ ì†ì‹¤í•¨ìˆ˜(loss function)ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ `ìŒì˜ ë¡œê·¸ ìš°ë„(negative log-likelihood)`ë¥¼\n",
        "êµ¬í˜„í•©ì‹œë‹¤. (ë‹¤ì‹œ ë§í•˜ì§€ë§Œ, ìš°ë¦¬ëŠ” í‘œì¤€ Pythonì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\n",
        "\n",
        "![](https://i.ibb.co/5WNgh0n/hU252jE.jpg)<br>\n",
        "[ì´ë¯¸ì§€ ì¶œì²˜ : https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/ ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOrnYfhlrF-y",
        "tags": []
      },
      "source": [
        "def nll(pred, target):\n",
        "    return -pred[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = nll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FzMqJXSrF-y"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. ìœ„ì—ì„œ ì •ì˜í•œ nllì˜ ë™ì‘ ë°©ì‹ì„ ì„¤ëª…í•˜ì—¬ ì£¼ì„¸ìš”.</b></p>\n",
        "    <p>ğŸ‘‰ (ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•´ ì£¼ì„¸ìš”)</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjiC4AxbrF-y"
      },
      "source": [
        "ìš°ë¦¬ì˜ ë¬´ì‘ìœ„ ëª¨ë¸ì— ëŒ€í•œ ì†ì‹¤ì„ ì ê²€í•´ë´…ì‹œë‹¤, ê·¸ëŸ¼ìœ¼ë¡œì¨ ìš°ë¦¬ëŠ” ë‚˜ì¤‘ì— ì—­ì „íŒŒ ì´í›„ì— ê°œì„ ì´ ìˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MmvM5zUrF-z",
        "tags": []
      },
      "source": [
        "yb =labels\n",
        "print(loss_func(preds, yb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OZataeTrF-z"
      },
      "source": [
        "#### d. accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcAPNDIlrF-0"
      },
      "source": [
        "ìš°ë¦¬ ëª¨ë¸ì˜ ì •í™•ë„(accuracy)ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ì‹œë‹¤. ë§¤ ì˜ˆì¸¡ë§ˆë‹¤, ë§Œì•½ ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ê°€ ëª©í‘œê°’(target value)ê³¼ ë™ì¼í•˜ë‹¤ë©´, ê·¸ ì˜ˆì¸¡ì€ ì˜¬ë°”ë¥¸ ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzndq0bCrF-0",
        "tags": []
      },
      "source": [
        "def accuracy(out, yb): # yb: y batch\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LscRM8grF-0"
      },
      "source": [
        "ìš°ë¦¬ì˜ ë¬´ì‘ìœ„ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ì ê²€í•´ ë´…ì‹œë‹¤, ê·¸ëŸ¼ìœ¼ë¡œì¨ ì†ì‹¤ì´ ê°œì„ ë¨ì— ë”°ë¼ì„œ ì •í™•ë„ê°€ ê°œì„ ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrFAVjV_rF-1",
        "tags": []
      },
      "source": [
        "print(accuracy(preds, yb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzDEX7zirF-1"
      },
      "source": [
        "### C. training loop(í›ˆë ¨ ë£¨í”„) ì •ì˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TluM9RhPrF-2"
      },
      "source": [
        "ì´ì œ ìš°ë¦¬ëŠ” í›ˆë ¨ ë£¨í”„(training loop)ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§¤ ë°˜ë³µë§ˆë‹¤, ìš°ë¦¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤:\n",
        "\n",
        "- ë°ì´í„°ì˜ ë¯¸ë‹ˆë°°ì¹˜ë¥¼ ì„ íƒ\n",
        "- ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "- ì†ì‹¤ ê³„ì‚°\n",
        "- ``loss.backward()`` ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì˜ ê¸°ìš¸ê¸° ì—…ë°ì´íŠ¸, ì´ ê²½ìš°ì—ëŠ”, ``weights`` ì™€ ``bias``.\n",
        "\n",
        "ì´ì œ ìš°ë¦¬ëŠ” ì´ ê¸°ìš¸ê¸°ë“¤ì„ ì´ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ì™€ ì ˆí¸ì„ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤.\n",
        "ìš°ë¦¬ëŠ” ì´ê²ƒì„ ``torch.no_grad()`` ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì ¸(context manager) ë‚´ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤,\n",
        "ì™œëƒí•˜ë©´ ì´ëŸ¬í•œ ì‹¤í–‰ì´ ë‹¤ìŒ ê¸°ìš¸ê¸°ì˜ ê³„ì‚°ì— ê¸°ë¡ë˜ì§€ ì•Šê¸°ë¥¼ ì›í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
        "PyTorchì˜ ìë™ ê¸°ìš¸ê¸°(Autograd)ê°€ ì–´ë–»ê²Œ ì—°ì‚°ì„ ê¸°ë¡í•˜ëŠ”ì§€\n",
        "[ì—¬ê¸°](https://pytorch.org/docs/stable/notes/autograd.html)ì—ì„œ ë” ì•Œì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ìš°ë¦¬ëŠ” ê·¸ëŸ¬ê³ ë‚˜ì„œ ê¸°ìš¸ê¸°ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤, ê·¸ëŸ¼ìœ¼ë¡œì¨ ë‹¤ìŒ ë£¨í”„(loop)ì— ì¤€ë¹„í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
        "ê·¸ë ‡ì§€ ì•Šìœ¼ë©´, ìš°ë¦¬ì˜ ê¸°ìš¸ê¸°ë“¤ì€ ì¼ì–´ë‚œ ëª¨ë“  ì—°ì‚°ì˜ ëˆ„ì  ì§‘ê³„ë¥¼ ê¸°ë¡í•˜ê²Œ ë˜ë²„ë¦½ë‹ˆë‹¤.\n",
        "(ì¦‰, ``loss.backward()`` ê°€ ì´ë¯¸ ì €ì¥ëœ ê²ƒì„ ëŒ€ì²´í•˜ê¸°ë³´ë‹¨, ê¸°ì¡´ ê°’ì— ê¸°ìš¸ê¸°ë¥¼ *ë”í•˜ê²Œ* ë©ë‹ˆë‹¤).\n",
        "\n",
        "<div class=\"alert alert-info\"><b>ğŸ“Œ Tip</b><p>ì—¬ëŸ¬ë¶„ë“¤ì€ PyTorch ì½”ë“œì— ëŒ€í•˜ì—¬ í‘œì¤€ python ë””ë²„ê±°(debugger)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë§¤ ë‹¨ê³„ë§ˆë‹¤ ë‹¤ì–‘í•œ ë³€ìˆ˜ ê°’ì„ ì ê²€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ  `set_trace()` ë¥¼ ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©í•´ë³´ì„¸ìš”.</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAZUjgePrF-4",
        "tags": []
      },
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "print(f'[before] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[before] acc : {accuracy(model(x_test), y_test)}')\n",
        "\n",
        "lr = 0.5  # í•™ìŠµë¥ (learning rate)\n",
        "epochs = 2  # í›ˆë ¨ì— ì‚¬ìš©í•  ì—í­(epoch) ìˆ˜\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for xb, yb in train_dl:\n",
        "#         set_trace()\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()\n",
        "            \n",
        "\n",
        "    # validation\n",
        "    with torch.no_grad():\n",
        "        val_loss, val_acc = 0, 0\n",
        "        for xb, yb in val_dl:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            val_loss += loss_func(model(xb), yb)\n",
        "            val_acc += accuracy(model(xb), yb)\n",
        "            \n",
        "    print(f'epoch {epoch+1} >>> val loss({val_loss / len(val_dl):.7f}), acc({val_acc / len(val_dl):.7f})')\n",
        "            \n",
        "print(f'[after ] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[after ] acc : {accuracy(model(x_test), y_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iLTKeaNrF-2"
      },
      "source": [
        "ì§€ë‚œ ì‹œê°„ ê¸°ìš¸ê¸°ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•´ ì£¼ì–´ì•¼í•˜ëŠ” ì´ìœ ì— ëŒ€í•˜ì—¬ ì§‘ê³  ë„˜ì–´ê°€ì§€ ì•Šì•„ ì•„ë˜ì˜ ë‚´ìš©ì„ ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤. ì½”ë“œëŠ” sin í•¨ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì‹ ê²½ë§ì´ê³ , í•™ìŠµ ê³¼ì €ì—ì„œ ê¸°ìš¸ê¸°ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì˜€ì„ ë•Œì™€ ê·¸ë ‡ì§€ ì•Šì„ ê²½ìš°ì˜ local gradientì˜ ë³€í™”ë¥¼ ì¶œë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì½”ë“œì™€ ì‹¤í–‰ê²°ê³¼ë¥¼ ë³´ê³  ì•„ë˜ì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E_9ks9HrF-5",
        "tags": []
      },
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "def get_grad_hist(mode):\n",
        "    dtype = torch.float\n",
        "\n",
        "    x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "    y = torch.sin(x)\n",
        "\n",
        "    a = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "    b = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "    c = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "    d = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "    grad_log = [[], [], [], []]\n",
        "\n",
        "    learning_rate = 1e-6\n",
        "    for t in range(2000):\n",
        "        y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "        loss = (y_pred - y).pow(2).sum()\n",
        "\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            a -= learning_rate * a.grad\n",
        "            b -= learning_rate * b.grad\n",
        "            c -= learning_rate * c.grad\n",
        "            d -= learning_rate * d.grad\n",
        "\n",
        "            grad_log[0].append(float(a.grad))\n",
        "            grad_log[1].append(float(b.grad))\n",
        "            grad_log[2].append(float(c.grad))\n",
        "            grad_log[3].append(float(d.grad))\n",
        "\n",
        "            if mode == 1:\n",
        "                # ê°€ì¤‘ì¹˜ ê°±ì‹  í›„ì—ëŠ” ë³€í™”ë„ë¥¼ ì§ì ‘ 0ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
        "                a.grad = None\n",
        "                b.grad = None\n",
        "                c.grad = None\n",
        "                d.grad = None\n",
        "                \n",
        "    return grad_log\n",
        "\n",
        "def show_grad(grad_log, title):\n",
        "    fig = plt.figure(figsize=(10, 4))\n",
        "\n",
        "    label = ['a', 'b', 'c', 'd']\n",
        "    for i in range(1, 5):\n",
        "        ax = fig.add_subplot(2, 2, i)\n",
        "        ax.plot(range(2000), grad_log[i-1], label=label[i-1])\n",
        "        ax.set_title(label[i-1])\n",
        "   \n",
        "    fig.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "grad_log_with_reset_gradient = get_grad_hist(1)\n",
        "grad_log_with_acc_gradient = get_grad_hist(0)\n",
        "\n",
        "show_grad(grad_log_with_acc_gradient, 'gradient change(no reset)')\n",
        "show_grad(grad_log_with_reset_gradient, 'gradient change(reset)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1DTc5VvrF-6"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    <p><b>Q. ìœ„ ì½”ë“œì˜ ì‹¤í–‰ê²°ê³¼ì—ì„œ ë‘ plotëŠ” í™•ì—°í•œ ì°¨ì´ë¥¼ ë³´ì…ë‹ˆë‹¤. ì´ëŸ°í•œ ì°¨ì´ë¥¼ ë³´ì´ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì´ê³  ì–´ë–¤ plotê°€ ì˜ í•™ìŠµë˜ê³  ìˆëŠ” ëª¨ë¸ì˜ plotì¼ê¹Œìš”?</b>  <a href=\"https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\">tip</a></p>\n",
        "    <p>ğŸ‘‰ (ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•´ ì£¼ì„¸ìš”)</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_bIlGrNrF-6"
      },
      "source": [
        "## 2. torch.nnì„ ì´ìš©í•œ ë¦¬íŒ©í† ë§\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD5__qgibEQs"
      },
      "source": [
        "ì´ì œ ìš°ë¦¬ëŠ” ì½”ë“œë¥¼ ë¦¬íŒ©í† ë§(refactoring) í•˜ê² ìŠµë‹ˆë‹¤, ê·¸ëŸ¼ìœ¼ë¡œì¨ ì´ì „ê³¼ ë™ì¼í•˜ì§€ë§Œ,\n",
        "PyTorchì˜ ``nn`` í´ë˜ìŠ¤ì˜ ì¥ì ì„ í™œìš©í•˜ì—¬ ë” ê°„ê²°í•˜ê³  ìœ ì—°í•˜ê²Œ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤.\n",
        "ì§€ê¸ˆë¶€í„° ë§¤ ë‹¨ê³„ì—ì„œ, ìš°ë¦¬ëŠ” ì½”ë“œë¥¼ ë” ì§§ê³ , ì´í•´í•˜ê¸° ì‰½ê³ , ìœ ì—°í•˜ê²Œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zejiCYUtbEQs"
      },
      "source": [
        "### A. torch.nn.functional ì‚¬ìš©í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR3NO_X4bEQs"
      },
      "source": [
        "ì²˜ìŒì´ë©´ì„œ ìš°ë¦¬ì˜ ì½”ë“œë¥¼ ì§§ê²Œ ë§Œë“¤ê¸° ê°€ì¥ ì‰¬ìš´ ë‹¨ê³„ëŠ” ì§ì ‘ ì‘ì„±í•œ <u>í™œì„±í™”, ì†ì‹¤ í•¨ìˆ˜</u>ë¥¼ ``torch.nn.functional`` ì˜ í•¨ìˆ˜ë¡œ ëŒ€ì²´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤(ê´€ë¡€ì— ë”°ë¼, ì¼ë°˜ì ìœ¼ë¡œ ``F`` ë„¤ì„ìŠ¤í˜ì´ìŠ¤(namespace)ë¥¼ í†µí•´ ì„í¬íŠ¸(import) í•©ë‹ˆë‹¤)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PayrGwRbEQs"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVmrAXiLbEQs"
      },
      "source": [
        "ì´ ëª¨ë“ˆì—ëŠ” ``torch.nn`` ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëª¨ë“  í•¨ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤(ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë‹¤ë¥¸ ë¶€ë¶„ì—ëŠ” í´ë˜ìŠ¤ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.) \n",
        "ë‹¤ì–‘í•œ ì†ì‹¤ ë° í™œì„±í™” í•¨ìˆ˜ ë¿ë§Œ ì•„ë‹ˆë¼, í’€ë§(pooling) í•¨ìˆ˜ì™€ ê°™ì´ ì‹ ê²½ë§ì„ ë§Œë“œëŠ”ë° í¸ë¦¬í•œ ëª‡ ê°€ì§€ í•¨ìˆ˜ë„ ì—¬ê¸°ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.(ì»¨ë³¼ë£¨ì…˜(convolution) ì—°ì‚°, ì„ í˜•(linear) ë ˆì´ì–´, ë“±ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ë„ ìˆì§€ë§Œ, ì•ìœ¼ë¡œ ë³´ì‹œê² ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë‹¤ë¥¸ ë¶€ë¶„ì„ ì‚¬ìš©í•˜ì—¬ ë” ì˜ ì²˜ë¦¬ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\n",
        "\n",
        "ë§Œì•½ ì—¬ëŸ¬ë¶„ë“¤ì´ ìŒì˜ ë¡œê·¸ ìš°ë„ ì†ì‹¤(nll)ê³¼ ë¡œê·¸ ì†Œí”„íŠ¸ë§¥ìŠ¤(log softmax) í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, PytorchëŠ” ì´ ë‘˜ì„ ê²°í•©í•˜ëŠ” ë‹¨ì¼ í•¨ìˆ˜ì¸ `F.cross_entropy`ë¥¼ ì œê³µí•©ë‹ˆë‹¤. \n",
        "\n",
        "ë”°ë¼ì„œ ëª¨ë¸ì—ì„œ í™œì„±í™” í•¨ìˆ˜ë¥¼ ì œê±°í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
        "- [[Pytorch] softmaxì™€ log_softmax (ê·¸ë¦¬ê³  CrossEntropyLoss)](https://junstar92.tistory.com/118)\n",
        "- [03. ì†Œí”„íŠ¸ë§¥ìŠ¤ íšŒê·€ì˜ ë¹„ìš© í•¨ìˆ˜ êµ¬í˜„í•˜ê¸°](https://wikidocs.net/60572)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM_wayykrF-6",
        "tags": []
      },
      "source": [
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "    return xb @ weights + bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXsaqDhbrF-7"
      },
      "source": [
        "ë”ì´ìƒ ``model`` í•¨ìˆ˜ì—ì„œ ``log_softmax`` ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.\n",
        "ì†ì‹¤ê³¼ ì •í™•ë„ê³¼ ì´ì „ê³¼ ë™ì¼í•œì§€ í™•ì¸í•´ë´…ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NQSJgFdrF-7",
        "tags": []
      },
      "source": [
        "print(loss_func(model(x_test), y_test), accuracy(model(x_test), y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "q7kq6MLEbEQt"
      },
      "source": [
        "### B. nn.Module ì„ ì´ìš©í•˜ì—¬ ë¦¬íŒ©í† ë§ í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Om_HBWjgbEQt"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ, ë” ëª…í™•í•˜ê³  ê°„ê²°í•œ í›ˆë ¨ ë£¨í”„ë¥¼ ìœ„í•´ ``nn.Module`` ë° ``nn.Parameter`` ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "ìš°ë¦¬ëŠ” ``nn.Module`` (ìì²´ê°€ í´ë˜ìŠ¤ì´ê³  ìƒíƒœë¥¼ ì¶”ì²™í•  ìˆ˜ ìˆëŠ”) í•˜ìœ„ í´ë˜ìŠ¤(subclass)ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
        "ì´ ê²½ìš°ì—ëŠ”, í¬ì›Œë“œ(forward) ë‹¨ê³„ì— ëŒ€í•œ ê°€ì¤‘ì¹˜, ì ˆí¸, ê·¸ë¦¬ê³  ë©”ì†Œë“œ(method) ë“±ì„ ìœ ì§€í•˜ëŠ”\n",
        "í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ê³ ì í•©ë‹ˆë‹¤.\n",
        "``nn.Module`` ì€ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ëª‡ ê°€ì§€ ì†ì„±(attribute)ê³¼ ë©”ì†Œë“œë¥¼ (``.parameters()`` ì™€\n",
        "``.zero_grad()`` ê°™ì€) ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "<div class=\"alert alert-info\"><b>ğŸ“Œ Note</b><p>`nn.Module`ì€ PyTorch ì˜ íŠ¹ì • ê°œë…ì´ê³ , ìš°ë¦¬ëŠ” ì´ í´ë˜ìŠ¤ë¥¼ ë§ì´ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. `nn.Module`ë¥¼ Pythonì˜ ì½”ë“œë¥¼ ì„í¬íŠ¸í•˜ê¸° ìœ„í•œ ì½”ë“œ íŒŒì¼ì¸ <a href=\"https://docs.python.org/3/tutorial/modules.html\">module</a>ì˜ ê°œë…ê³¼ í—·ê°ˆë¦¬ì§€ ë§ì•„ì£¼ì„¸ìš”.</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Gtq-YEeMbEQt"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "        self.bias = nn.Parameter(torch.zeros(10))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return xb @ self.weights + self.bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T23:02:40.235911Z",
          "iopub.status.busy": "2021-09-30T23:02:40.234914Z",
          "iopub.status.idle": "2021-09-30T23:02:40.258853Z",
          "shell.execute_reply": "2021-09-30T23:02:40.256891Z",
          "shell.execute_reply.started": "2021-09-30T23:02:40.235911Z"
        },
        "id": "zqcsX1rFbEQt"
      },
      "source": [
        "í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ ì— ì´ì œëŠ” ì˜¤ë¸Œì íŠ¸(object) ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—,\n",
        "ë¨¼ì € ëª¨ë¸ì„ ì¸ìŠ¤í„´ìŠ¤í™”(instantiate) í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "F9ZubD_XbEQt"
      },
      "source": [
        "model = Mnist_Logistic()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naugN4tQbEQu"
      },
      "source": [
        "ì´ì œ ìš°ë¦¬ëŠ” ì´ì „ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì†ì‹¤ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì—¬ê¸°ì„œ ``nn.Module`` ì˜¤ë¸Œì íŠ¸ë“¤ì€ ë§ˆì¹˜ í•¨ìˆ˜ì²˜ëŸ¼ ì‚¬ìš©ë©ë‹ˆë‹¤ (ì¦‰, ì´ë“¤ì€ *í˜¸ì¶œê°€ëŠ¥* í•©ë‹ˆë‹¤),\n",
        "ê·¸ëŸ¬ë‚˜ ë°°í›„ì—ì„œ Pytorch ëŠ” ìš°ë¦¬ì˜ ``forward`` ë©”ì†Œë“œë¥¼ ìë™ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HQfomeBYbEQu"
      },
      "source": [
        "print(loss_func(model(x_test), y_test), accuracy(model(x_test), y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxZcGWujbEQu"
      },
      "source": [
        "ì´ì „ì—ëŠ” í›ˆë ¨ ë£¨í”„ë¥¼ ìœ„í•´ ì´ë¦„ ë³„ë¡œ ê° ë§¤ê°œë³€ìˆ˜(parameter)ì˜ ê°’ì„ ì—…ë°ì´íŠ¸í•˜ê³  ë‹¤ìŒê³¼ ê°™ì´\n",
        "ê° ë§¤ê°œ ë³€ìˆ˜ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ìˆ˜ë™ìœ¼ë¡œ 0ìœ¼ë¡œ ì œê±°í•´ì•¼ í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    weights -= weights.grad * lr\n",
        "    bias -= bias.grad * lr\n",
        "    weights.grad.zero_()\n",
        "    bias.grad.zero_()\n",
        "```\n",
        "\n",
        "ì´ì œ ìš°ë¦¬ëŠ” model.parameters() ë° model.zero_grad() (ëª¨ë‘ ``nn.Module`` ì— ëŒ€í•´ PyTorchì— ì˜í•´ ì •ì˜ë¨)ë¥¼ í™œìš©í•˜ì—¬ ì´ëŸ¬í•œ ë‹¨ê³„ë¥¼ ë” ê°„ê²°í•˜ê²Œ ë§Œë“¤ê³ , íŠ¹íˆ ë” ë³µì¡í•œ ëª¨ë¸ì— ëŒ€í•´ì„œ ì¼ë¶€ ë§¤ê°œë³€ìˆ˜ë¥¼ ìŠì–´ ë²„ë¦¬ëŠ” ì˜¤ë¥˜ë¥¼ ëœ ë°œìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "        model.zero_grad()\n",
        "```\n",
        "\n",
        "ì´ì œ ì´ê²ƒì„ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ``fit`` í•¨ìˆ˜ë¡œ ì‘ì€ í›ˆë ¨ ë£¨í”„ë¥¼ ê°ìŒ€ ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "í›ˆë ¨ ì „ì— í•­ìƒ `model.train()`ì„ í˜¸ì¶œí•˜ê³ , ì¶”ë¡ (inference) ì „ì— `model.eval()`ì„ í˜¸ì¶œí•©ë‹ˆë‹¤, ì´ëŠ” `nn.BatchNorm2d` ë° `nn.Dropout`ê³¼ ê°™ì€ ë ˆì´ì–´ì—ì„œ ì´ëŸ¬í•œ ë‹¤ë¥¸ ë‹¨ê³„(í›ˆë ¨, ì¶”ë¡ ) ì— ëŒ€í•œ ì ì ˆí•œ ë™ì‘ì´ ì¼ì–´ë‚˜ê²Œ í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "zt1iXErnbEQu"
      },
      "source": [
        "def fit(model, train_dl, val_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_acc = 0, 0\n",
        "            for xb, yb in val_dl:\n",
        "                xb = xb.to(device)\n",
        "                yb = yb.to(device)\n",
        "                val_loss += loss_func(model(xb), yb)\n",
        "                val_acc += accuracy(model(xb), yb)\n",
        "\n",
        "            print(f'epoch {epoch+1} >>> val loss({val_loss / len(val_dl):.7f}), acc({val_acc / len(val_dl):.7f})')\n",
        "\n",
        "\n",
        "print(f'[before] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[before] acc : {accuracy(model(x_test), y_test)}')\n",
        "\n",
        "lr = 0.5  # í•™ìŠµë¥ (learning rate)\n",
        "epochs = 2  # í›ˆë ¨ì— ì‚¬ìš©í•  ì—í­(epoch) ìˆ˜\n",
        "fit(model, train_dl, val_dl)\n",
        "\n",
        "print(f'[after ] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[after ] acc : {accuracy(model(x_test), y_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T23:11:38.015066Z",
          "iopub.status.busy": "2021-09-30T23:11:38.015066Z",
          "iopub.status.idle": "2021-09-30T23:11:38.028031Z",
          "shell.execute_reply": "2021-09-30T23:11:38.026035Z",
          "shell.execute_reply.started": "2021-09-30T23:11:38.015066Z"
        },
        "id": "_Oqs8dX0bEQu"
      },
      "source": [
        "### C. nn.Linear ë¥¼ ì´ìš©í•˜ì—¬ ë¦¬íŒ©í† ë§ í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_vFGn0MbEQu"
      },
      "source": [
        "ê³„ì†í•´ì„œ ì½”ë“œë¥¼ ë¦¬íŒ©í† ë§ í•©ë‹ˆë‹¤. `self.weights` ë° `self.bias`ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì •ì˜ ë° ì´ˆê¸°í™”í•˜ê³ , `xb  @ self.weights + self.bias`ë¥¼ ê³„ì‚°í•˜ëŠ” ëŒ€ì‹ ì—, ìœ„ì˜ ëª¨ë“  ê²ƒì„ í•´ì¤„ Pytorch í´ë˜ìŠ¤ì¸ [nn.Linear](https://pytorch.org/docs/stable/nn.html#linear-layers)ë¥¼ ì„ í˜• ë ˆì´ì–´ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "Pytorchì—ëŠ” ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì½”ë“œë¥¼ í¬ê²Œ ë‹¨ìˆœí™” í•  ìˆ˜ ìˆëŠ” ë¯¸ë¦¬ ì •ì˜ëœ ë ˆì´ì–´ê°€ ìˆê³  ì´ëŠ” ë˜í•œ ì¢…ì¢… ê¸°ì¡´ ì½”ë“œë³´ë‹¤ ì†ë„ë¥¼ ë¹ ë¥´ê²Œ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eain_A2cbEQv"
      },
      "source": [
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuLl6VifbEQv"
      },
      "source": [
        "ì´ì „ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì„ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ê³  ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "_yEXllmzbEQv"
      },
      "source": [
        "model = Mnist_Logistic().to(device)\n",
        "print(loss_func(model(x_test), y_test), accuracy(model(x_test), y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBIiaBMNbEQv"
      },
      "source": [
        "ìš°ë¦¬ëŠ” ì—¬ì „íˆ ì´ì „ê³¼ ë™ì¼í•œ `fit` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "V0Qb8XOpbEQv"
      },
      "source": [
        "print(f'[before] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[before] acc : {accuracy(model(x_test), y_test)}')\n",
        "\n",
        "lr = 0.5  # í•™ìŠµë¥ (learning rate)\n",
        "epochs = 2  # í›ˆë ¨ì— ì‚¬ìš©í•  ì—í­(epoch) ìˆ˜\n",
        "fit(model, train_dl, val_dl)\n",
        "\n",
        "print(f'[after ] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[after ] acc : {accuracy(model(x_test), y_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSVzrGQ6bEQv"
      },
      "source": [
        "## 3. optmì„ ì´ìš©í•˜ì—¬ ë¦¬íŒ©í† ë§ í•˜ê¸°\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfyizBnfbEQw"
      },
      "source": [
        "Pytorchì—ëŠ” ë‹¤ì–‘í•œ ìµœì í™”(optimization) ì•Œê³ ë¦¬ì¦˜ì„ ê°€ì§„ íŒ¨í‚¤ì§€ì¸ `torch.optim`ë„ ìˆìŠµë‹ˆë‹¤.\n",
        "ê° ë§¤ê°œë³€ìˆ˜ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ í•˜ëŠ” ëŒ€ì‹ , ì˜µí‹°ë§ˆì´ì €(optimizer)ì˜ `step` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬\n",
        "ì—…ë°ì´íŠ¸ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ë ‡ê²Œ í•˜ë©´ ì´ì „ì— ìˆ˜ë™ìœ¼ë¡œ ì½”ë”©í•œ ìµœì í™” ë‹¨ê³„ë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "\n",
        "ëŒ€ì‹ ì— ì´ë ‡ê²Œ ë§ì´ì£ :\n",
        "```python\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```\n",
        "\n",
        "(`optim.zero_grad()` ëŠ” ê¸°ìš¸ê¸°ë¥¼ 0ìœ¼ë¡œ ì¬ì„¤ì • í•´ì¤ë‹ˆë‹¤. ë‹¤ìŒ ë¯¸ë‹ˆ ë°°ì¹˜ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•˜ê¸° ì „ì— í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QyQlGGmbEQw"
      },
      "source": [
        "from torch import optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPYS8HuQbEQw"
      },
      "source": [
        "ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ëª¨ë¸ê³¼ ì˜µí‹°ë§ˆì´ì ¸ë¥¼ ë§Œë“œëŠ” ì‘ì€ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "iCUm1c2SbEQw"
      },
      "source": [
        "def get_model():\n",
        "    model = Mnist_Logistic().to(device)\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ixK2iePLbEQw"
      },
      "source": [
        "model, opt = get_model()\n",
        "\n",
        "print(f'[before] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[before] acc : {accuracy(model(x_test), y_test)}')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss, val_acc = 0, 0\n",
        "        for xb, yb in val_dl:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            val_loss += loss_func(model(xb), yb)\n",
        "            val_acc += accuracy(model(xb), yb)\n",
        "\n",
        "    print(f'epoch {epoch+1} >>> val loss({val_loss / len(val_dl):.7f}), acc({val_acc / len(val_dl):.7f})')\n",
        "        \n",
        "print(f'[after ] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[after ] acc : {accuracy(model(x_test), y_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i33fIHO8bEQw"
      },
      "source": [
        "## 4. fit() ì™€ get_data() ìƒì„±í•˜ê¸°\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3CHklr-bEQx"
      },
      "source": [
        "ì´ì œ ìš°ë¦¬ëŠ” ìš°ë¦¬ë§Œì˜ ì‘ì€ ë¦¬íŒ©í† ë§ì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤.\n",
        "í›ˆë ¨ ë°ì´í„°ì…‹ê³¼ ê²€ì¦ ë°ì´í„°ì…‹ ëª¨ë‘ì— ëŒ€í•œ ì†ì‹¤ì„ ê³„ì‚°í•˜ëŠ” ìœ ì‚¬í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‘ ë²ˆ ê±°ì¹˜ë¯€ë¡œ,\n",
        "ì´ë¥¼ í•˜ë‚˜ì˜ ë°°ì¹˜ì— ëŒ€í•œ ì†ì‹¤ì„ ê³„ì‚°í•˜ëŠ” ìì²´ í•¨ìˆ˜ ``loss_batch`` ë¡œ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "í›ˆë ¨ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì „ë‹¬í•˜ê³  ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—­ì „íŒŒë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "ê²€ì¦ ë°ì´í„°ì…‹ì˜ ê²½ìš° ì˜µí‹°ë§ˆì´ì €ë¥¼ ì „ë‹¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë©”ì†Œë“œê°€ ì—­ì „íŒŒë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lHy0X2RbEQx"
      },
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "    loss = loss_func(model(xb), yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), len(xb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CDTnRYzbEQx"
      },
      "source": [
        "`fit` ì€ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ê° ì—í­ì— ëŒ€í•œ í›ˆë ¨ ë° ê²€ì¦ ì†ì‹¤ì„ ê³„ì‚°í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "wR7FnylibEQx"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, val_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            loss_batch(model, loss_func, xb, yb, opt)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in val_dl]\n",
        "            )\n",
        "\n",
        "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "\n",
        "        print(epoch, val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "k3LnlbpZbEQx"
      },
      "source": [
        "def get_data(train_ds, valid_ds, bs):\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
        "        DataLoader(valid_ds, batch_size=bs*2), # ê²€ì¦ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œëŠ” ì—­ì „íŒŒ(backpropagation)ê°€ í•„ìš”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ \n",
        "                                               # ë©”ëª¨ë¦¬ë¥¼ ëœ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ëŠ˜ë¦´ ìˆ˜ ìˆë‹¤.\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T23:39:14.705123Z",
          "iopub.status.busy": "2021-09-30T23:39:14.704128Z",
          "iopub.status.idle": "2021-09-30T23:39:14.716056Z",
          "shell.execute_reply": "2021-09-30T23:39:14.714096Z",
          "shell.execute_reply.started": "2021-09-30T23:39:14.705123Z"
        },
        "id": "-ZEKkuDfbEQx"
      },
      "source": [
        "`get_data`ëŠ” í•™ìŠµ ë° ê²€ì¦ ë°ì´í„°ì…‹ì— ëŒ€í•œ dataloader ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "_gWjjG9JbEQx"
      },
      "source": [
        "bs = 64\n",
        "train_dl, val_dl = get_data(train_ds, val_ds, bs)\n",
        "model, opt = get_model()\n",
        "\n",
        "print(f'[before] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[before] acc : {accuracy(model(x_test), y_test)}')\n",
        "\n",
        "fit(epochs, model, loss_func, opt, train_dl, val_dl)\n",
        "\n",
        "print(f'[after ] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[after ] acc : {accuracy(model(x_test), y_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejh_NKAtbEQx"
      },
      "source": [
        "ì´ëŸ¬í•œ ê¸°ë³¸ 3ì¤„ì˜ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br>\n",
        "ì»¨ë³¼ë£¨ì…˜ ì‹ ê²½ë§(CNN)ì„ í›ˆë ¨í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fludhfbRbEQx"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "    <h2>ğŸ“Œ ì¤‘ê°„ì •ë¦¬</h2>\n",
        "    <p>ì§€ê¸ˆê¹Œì§€ MNIST Fashion datasetì„ ë¶„ë¥˜í•˜ëŠ” ê°„ë‹¨í•œ ì„ í˜• ë¶„ë¥˜ê¸°ë¥¼ ì•„ë˜ì˜ ë‹¨ê³„ë¥¼ ê±¸ì¹˜ë©° ë³€í˜•ì‹œì¼œ ë³´ì•˜ìŠµë‹ˆë‹¤.</p>\n",
        "    <div>\n",
        "        â€¢ Tensorì™€ autogradë§Œì„ ì´ìš©í•œ ì‹ ê²½ë§ êµ¬ì¶•<br>\n",
        "        â€¢ nn.functionalì„ ì´ìš©í•˜ì—¬ í™œì„±í™” í•¨ìˆ˜/ì†ì‹¤ í•¨ìˆ˜ ëŒ€ì²´ ğŸ‘‰ í•´ë‹¹ í•¨ìˆ˜ë“¤ì„ ì§ì ‘ ì‘ì„±í•˜ì§€ ì•Šì•„ë„ ë˜ê²Œ ë¨<br>\n",
        "        â€¢ nn.Moduleë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì„ ëª¨ë“ˆí™” ğŸ‘‰ gradient ì´ˆê¸°í™”ê°€ ê°„í¸í•´ì§<br>\n",
        "        â€¢ nn.Linearë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ ì •ì˜ ğŸ‘‰ ê°€ì¤‘ì¹˜/í¸í–¥ ì´ˆê¸°í™”ì™€ forwardë¥¼ ì§ì ‘ ì‘ì„±í•˜ì§€ ì•Šì•„ë„ ë˜ê²Œ ë¨<br>\n",
        "        â€¢ optmì„ ì´ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T23:53:58.762438Z",
          "iopub.status.busy": "2021-09-30T23:53:58.761438Z",
          "iopub.status.idle": "2021-09-30T23:53:58.776395Z",
          "shell.execute_reply": "2021-09-30T23:53:58.774434Z",
          "shell.execute_reply.started": "2021-09-30T23:53:58.762438Z"
        },
        "id": "SMdAKe8qbEQy"
      },
      "source": [
        "## 5. CNN ìœ¼ë¡œ ë„˜ì–´ê°€ê¸°\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kcLzFnjbEQy"
      },
      "source": [
        "ì´ì œ 3ê°œì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë¡œ ì‹ ê²½ë§ì„ êµ¬ì¶•í•  ê²ƒì…ë‹ˆë‹¤.\n",
        "ì´ì „ ì„¹ì…˜ì˜ ì–´ë–¤ í•¨ìˆ˜ë„ ëª¨ë¸ì˜ í˜•ì‹ì— ëŒ€í•´ ê°€ì •í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—,\n",
        "ë³„ë„ì˜ ìˆ˜ì •ì—†ì´ CNNì„ í•™ìŠµí•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJxIP3RtbEQy"
      },
      "source": [
        "### A. nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY7IRB1GbEQy"
      },
      "source": [
        "Pytorch ì˜ ì‚¬ì „ì •ì˜ëœ [Conv2d](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) í´ë˜ìŠ¤ë¥¼ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. 3ê°œì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë¡œ CNNì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "ê° ì»¨ë³¼ë£¨ì…˜ ë’¤ì—ëŠ” ReLUê°€ ìˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ í‰ê·  í’€ë§(average pooling)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.(`view` ëŠ” PyTorchì˜ numpy `reshape` ë²„ì „ì…ë‹ˆë‹¤.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykAPgE4DbEQy"
      },
      "source": [
        "class Mnist_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        xb = xb.view(-1, 1, 28, 28)\n",
        "        xb = F.relu(self.conv1(xb))\n",
        "        xb = F.relu(self.conv2(xb))\n",
        "        xb = F.relu(self.conv3(xb))\n",
        "        xb = F.avg_pool2d(xb, 4)\n",
        "        return xb.view(-1, xb.size(1))\n",
        "\n",
        "lr = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T23:55:57.953135Z",
          "iopub.status.busy": "2021-09-30T23:55:57.952181Z",
          "iopub.status.idle": "2021-09-30T23:55:57.964104Z",
          "shell.execute_reply": "2021-09-30T23:55:57.962110Z",
          "shell.execute_reply.started": "2021-09-30T23:55:57.952181Z"
        },
        "id": "IHelDglRbEQy"
      },
      "source": [
        "[ëª¨ë©˜í…€(Momentum)](https://cs231n.github.io/neural-networks-3/#sgd)ì€ ì´ì „ ì—…ë°ì´íŠ¸ë„ ê³ ë ¤í•˜ê³  ì¼ë°˜ì ìœ¼ë¡œ ë” ë¹ ë¥¸ í›ˆë ¨ìœ¼ë¡œ ì´ì–´ì§€ëŠ” í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•(stochastic gradient descent)\n",
        "ì˜ ë³€í˜•ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "BTTB-udMbEQy"
      },
      "source": [
        "model = Mnist_CNN()\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "print(f'[before] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[before] acc : {accuracy(model(x_test), y_test)}')\n",
        "\n",
        "fit(epochs, model, loss_func, opt, train_dl, val_dl)\n",
        "\n",
        "print(f'[after ] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[after ] acc : {accuracy(model(x_test), y_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Ki56XsbEQy"
      },
      "source": [
        "### B. nn.Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpKj_DBabEQz"
      },
      "source": [
        "`torch.nn`ì—ëŠ” ì½”ë“œë¥¼ ê°„ë‹¨íˆ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë˜ ë‹¤ë¥¸ í¸ë¦¬í•œ í´ë˜ìŠ¤ì¸[Sequential](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential)ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "`Sequential` ê°ì²´ëŠ” ê·¸ ì•ˆì— í¬í•¨ëœ ê° ëª¨ë“ˆì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ê²ƒì€ ìš°ë¦¬ì˜ ì‹ ê²½ë§ì„ ì‘ì„±í•˜ëŠ” ë” ê°„ë‹¨í•œ ë°©ë²•ì…ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "ì´ë¥¼ í™œìš©í•˜ë ¤ë©´ ì£¼ì–´ì§„ í•¨ìˆ˜ì—ì„œ **ì‚¬ìš©ìì •ì˜ ë ˆì´ì–´(custom layer)** ë¥¼ ì‰½ê²Œ ì •ì˜í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, PyTorchì—ëŠ” `view` ë ˆì´ì–´ê°€ ì—†ìœ¼ë¯€ë¡œ ìš°ë¦¬ì˜ ì‹ ê²½ë§ ìš©ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "`Lambda` ëŠ” `Sequential` ë¡œ ì‹ ê²½ë§ì„ ì •ì˜í•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë ˆì´ì–´ë¥¼ ìƒì„±í•  ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMSpNM92bEQz"
      },
      "source": [
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "    return x.view(-1, 1, 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T23:58:34.931240Z",
          "iopub.status.busy": "2021-09-30T23:58:34.930243Z",
          "iopub.status.idle": "2021-09-30T23:58:34.950191Z",
          "shell.execute_reply": "2021-09-30T23:58:34.948193Z",
          "shell.execute_reply.started": "2021-09-30T23:58:34.931240Z"
        },
        "id": "d_0ADJcgbEQ0"
      },
      "source": [
        "`Sequential` ë¡œ ìƒì„±ëœ ëª¨ë¸ì€ ê°„ë‹¨í•˜ê²Œ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "5kc_GPXTbEQ0"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    Lambda(preprocess),\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AvgPool2d(4),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "print(f'[before] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[before] acc : {accuracy(model(x_test), y_test)}')\n",
        "\n",
        "fit(epochs, model, loss_func, opt, train_dl, val_dl)\n",
        "\n",
        "print(f'[after ] loss : {loss_func(model(x_test), y_test)}')\n",
        "print(f'[after ] acc : {accuracy(model(x_test), y_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWqYKNzibEQ0"
      },
      "source": [
        "### C. DataLoader ê°ì‹¸ê¸°\n",
        "---\n",
        "\n",
        "ìš°ë¦¬ì˜ CNNì€ ìƒë‹¹íˆ ê°„ê²°í•˜ì§€ë§Œ, MNISTì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤, ì™œëƒí•˜ë©´:\n",
        " - ì…ë ¥ì´ 28\\*28ì˜ ê¸´ ë²¡í„°ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
        " - ìµœì¢…ì ìœ¼ë¡œ CNN ê·¸ë¦¬ë“œ í¬ê¸°ëŠ” 4\\*4 ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤. (ì´ê²ƒì€ ìš°ë¦¬ê°€ ì‚¬ìš©í•œ í‰ê·  í’€ë§ ì»¤ë„ í¬ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.)\n",
        "\n",
        "ì´ ë‘ ê°€ì§€ ê°€ì •ì„ ì œê±°í•˜ì—¬ ëª¨ë¸ì´ ëª¨ë“  2d ë‹¨ì¼ ì±„ë„(channel) ì´ë¯¸ì§€ì—ì„œ ì‘ë™í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "ë¨¼ì € ì´ˆê¸° Lambda ë ˆì´ì–´ë¥¼ ì œê±°í•˜ê³  ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì œë„¤ë ˆì´í„°(generator)ë¡œ ì´ë™ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ou_9lx-5bEQ0"
      },
      "source": [
        "def preprocess(x, y):\n",
        "    return x.view(-1, 1, 28, 28), y\n",
        "\n",
        "\n",
        "class WrappedDataLoader:\n",
        "    def __init__(self, dl, func):\n",
        "        self.dl = dl\n",
        "        self.func = func\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "    def __iter__(self):\n",
        "        batches = iter(self.dl)\n",
        "        for b in batches:\n",
        "            yield (self.func(*b))\n",
        "\n",
        "train_dl, val_dl = get_data(train_ds, val_ds, bs)\n",
        "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
        "val_dl = WrappedDataLoader(val_dl, preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AzbL7b0bEQ0"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ ``nn.AvgPool2d`` ë¥¼ ``nn.AdaptiveAvgPool2d`` ë¡œ ëŒ€ì²´í•˜ì—¬ ìš°ë¦¬ê°€ ê°€ì§„\n",
        "*ì…ë ¥* í…ì„œê°€ ì•„ë‹ˆë¼ ì›í•˜ëŠ” *ì¶œë ¥* í…ì„œì˜ í¬ê¸°ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ê²°ê³¼ì ìœ¼ë¡œ ìš°ë¦¬ ëª¨ë¸ì€ ëª¨ë“  í¬ê¸°ì˜ ì…ë ¥ê³¼ í•¨ê»˜ ì‘ë™í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "XCNpms3IbEQ1"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T5b65ejbEQ1"
      },
      "source": [
        "í•œë²ˆ ì‹¤í–‰í•´ ë´…ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "x7e8OGnPbEQ1"
      },
      "source": [
        "fit(epochs, model, loss_func, opt, train_dl, val_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkgq7mKfbEQ1"
      },
      "source": [
        "## ë§ˆì¹˜ë©´ì„œ\n",
        "---\n",
        "\n",
        "ì´ì œ Pytorchë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¼ë°˜ ë°ì´í„° íŒŒì´í”„ ë¼ì¸ê³¼\n",
        "í›ˆë ¨ ë£¨í”„ê°€ ìˆìŠµë‹ˆë‹¤.\n",
        "ì´ì œ ëª¨ë¸ í•™ìŠµì´ ì–¼ë§ˆë‚˜ ê°„ë‹¨í•œì§€ í™•ì¸í•˜ë ¤ë©´ `mnist_sample` ìƒ˜í”Œ ë…¸íŠ¸ë¶ì„ ì‚´í´ë³´ì„¸ìš”.\n",
        "\n",
        "ë¬¼ë¡  ë°ì´í„° ì¦ê°•(data augmentation), ì´ˆë§¤ê°œë³€ìˆ˜ ì¡°ì •(hyperparameter tuning),\n",
        "í›ˆë ¨ê³¼ì • ëª¨ë‹ˆí„°ë§(monitoring training), ì „ì´ í•™ìŠµ(transfer learning) ë“±ê³¼ ê°™ì´\n",
        "ì¶”ê°€í•˜ê³  ì‹¶ì€ í•­ëª©ë“¤ì´ ë§ì´ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
        "ì´ëŸ¬í•œ ê¸°ëŠ¥ë“¤ì€ ì´ íŠœí† ë¦¬ì–¼ì— í‘œì‹œëœ ê²ƒê³¼ ë™ì¼í•œ ì„¤ê³„ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê°œë°œëœ fastai ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ\n",
        "ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ëª¨ë¸ì„ ë”ìš± ë°œì „ì‹œí‚¤ë ¤ëŠ” ì‹¤ë¬´ìì—ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ íŠœí† ë¦¬ì–¼ì˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ``torch.nn``, ``torch.optim``, ``Dataset``,\n",
        "ê·¸ë¦¬ê³  ``DataLoader`` ì˜ ê° ì˜ˆì œë¥¼ í†µí•´ ì„¤ëª…í•˜ê² ë‹¤ê³  ì´ì•¼ê¸°í–ˆì—ˆìŠµë‹ˆë‹¤.\n",
        "ì´ì œ ìœ„ì˜ ë‚´ìš©ë“¤ì„ ìš”ì•½í•´ë³´ê² ìŠµë‹ˆë‹¤:\n",
        "\n",
        " - **torch.nn**\n",
        "\n",
        "   + ``Module``: í•¨ìˆ˜ì²˜ëŸ¼ ë™ì‘í•˜ì§€ë§Œ, ë˜í•œ ìƒíƒœ(state) (ì˜ˆë¥¼ ë“¤ì–´, ì‹ ê²½ë§ì˜ ë ˆì´ì–´ ê°€ì¤‘ì¹˜)ë¥¼\n",
        "     í¬í•¨í•  ìˆ˜ ìˆëŠ” í˜¸ì¶œ ê°€ëŠ¥í•œ ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "     ì´ëŠ” í¬í•¨ëœ ``Parameter`` (ë“¤)ê°€ ì–´ë–¤ ê²ƒì¸ì§€ ì•Œê³ , ëª¨ë“  ê¸°ìš¸ê¸°ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ê³  ê°€ì¤‘ì¹˜\n",
        "     ì—…ë°ì´íŠ¸ ë“±ì„ ìœ„í•´ ë°˜ë³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "   + ``Parameter``: ``Module`` ì— ì—­ì „íŒŒ ë™ì•ˆ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê°€ì¤‘ì¹˜ê°€ ìˆìŒì„ ì•Œë ¤ì£¼ëŠ”\n",
        "     í…ì„œìš© ë˜í¼ì…ë‹ˆë‹¤. `requires_grad` ì†ì„±ì´ ì„¤ì •ëœ í…ì„œë§Œ ì—…ë°ì´íŠ¸ ë©ë‹ˆë‹¤.\n",
        "   + ``functional``: í™œì„±í™” í•¨ìˆ˜, ì†ì‹¤ í•¨ìˆ˜ ë“±ì„ í¬í•¨í•˜ëŠ” ëª¨ë“ˆ (ê´€ë¡€ì— ë”°ë¼ ì¼ë°˜ì ìœ¼ë¡œ\n",
        "     ``F`` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ì„í¬íŠ¸ ë©ë‹ˆë‹¤) ì´ê³ , ë¬¼ë¡  ì»¨ë³¼ë£¨ì…˜ ë° ì„ í˜• ë ˆì´ì–´ ë“±ì— ëŒ€í•´ì„œ\n",
        "     ìƒíƒœë¥¼ ì €ì¥í•˜ì§€ì•ŠëŠ”(non-stateful) ë²„ì „ì˜ ë ˆì´ì–´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
        " - ``torch.optim``: ì—­ì „íŒŒ ë‹¨ê³„ì—ì„œ ``Parameter`` ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ”,\n",
        "   ``SGD`` ì™€ ê°™ì€ ì˜µí‹°ë§ˆì´ì €ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
        " - ``Dataset``: ``TensorDataset`` ê³¼ ê°™ì´ Pytorchì™€ í•¨ê»˜ ì œê³µë˜ëŠ” í´ë˜ìŠ¤ë¥¼ í¬í•¨í•˜ì—¬ ``__len__`` ë°\n",
        "   ``__getitem__`` ì´ ìˆëŠ” ê°ì²´ì˜ ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤\n",
        " - ``DataLoader``: ëª¨ë“  ì¢…ë¥˜ì˜ ``Dataset`` ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ì˜ ë°°ì¹˜ë“¤ì„ ì¶œë ¥í•˜ëŠ” ë°˜ë³µì(iterator)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n"
      ]
    }
  ]
}