{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "aiffel",
      "language": "python",
      "name": "aiffel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "day1_problem_solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jieunjeon/study-pytorch/blob/main/day1_problem_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9006b4c3-3c09-42ae-88de-8fd66d1b9a89"
      },
      "source": [
        "# 이웃집 토토치 파이토치 : Day 1 - 추가 실습\n",
        "---"
      ],
      "id": "9006b4c3-3c09-42ae-88de-8fd66d1b9a89"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "062e1ab3-039b-40f1-adae-9ef8e59f615d"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "id": "062e1ab3-039b-40f1-adae-9ef8e59f615d",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ade02908-8f10-479e-8923-c2c90f839dfd"
      },
      "source": [
        "## Autograd\n",
        "---"
      ],
      "id": "ade02908-8f10-479e-8923-c2c90f839dfd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dc95d8f-0e73-4f30-ae5e-46bb3edadb34"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h4>Q1-1</h4>\n",
        "    <p> 아래과 같은 computational graph가 주어졌을 때, `y`를 `x`에 대한 식으로 표현하고, x가 1일 때의 gradient를 구하라.</p>\n",
        "    <img src=\"https://i.ibb.co/rdZLTvv/p-1.png\" alt=\"q1\" border=\"1\">\n",
        "    <div>\n",
        "        👉 y = x + 2<br>\n",
        "        👉 δy/δx = 1<br>\n",
        "    </div>\n",
        "</div>"
      ],
      "id": "5dc95d8f-0e73-4f30-ae5e-46bb3edadb34"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ba6356-c25d-4aa7-a119-1a462b0a2e2c"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h4>Q1-2</h4>\n",
        "    <p> 위의 사항을 코드로 구현하고, autograd를 통하여 구해진 x의 gradient와 위에서 계산해 낸 gradient가 일치하는지 확인하라.</p>\n",
        "</div>"
      ],
      "id": "91ba6356-c25d-4aa7-a119-1a462b0a2e2c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88cb2a31-2b54-451c-9bcf-3e17860f8ec9",
        "outputId": "8f062f1d-3d78-4819-f7d5-24f1a5a420e5"
      },
      "source": [
        "x = torch.ones(1, requires_grad=True)\n",
        "y = x + 2\n",
        "print(f'before backward 👉 x : {x}\\ty:{y}')\n",
        "\n",
        "y.backward()\n",
        "print(f'after  backward 👉 x : {x}\\ty:{y}')\n",
        "print(f'after  backward 👉 x.grad : {x.grad}')"
      ],
      "id": "88cb2a31-2b54-451c-9bcf-3e17860f8ec9",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before backward 👉 x : tensor([1.], requires_grad=True)\ty:tensor([3.], grad_fn=<AddBackward0>)\n",
            "after  backward 👉 x : tensor([1.], requires_grad=True)\ty:tensor([3.], grad_fn=<AddBackward0>)\n",
            "after  backward 👉 x.grad : tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff01bbb7-66db-4a22-b97b-357919d21759"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h4>Q2-1</h4>\n",
        "    <p> 아래과 같은 computational graph가 주어졌을 때, `y`를 `x`에 대한 식으로 표현하고, x가 1일 때의 gradient를 구하라.</p>\n",
        "    <img src=\"https://i.ibb.co/7VVRcs5/p-2.png\" alt=\"q2\" border=\"1\">\n",
        "    <div>\n",
        "        👉 y = 2x<br>\n",
        "        👉 δy/δx = 2<br>\n",
        "    </div>\n",
        "</div>"
      ],
      "id": "ff01bbb7-66db-4a22-b97b-357919d21759"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98791695-0c59-40c8-aeb0-dd33e1a036a4"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h4>Q2-2</h4>\n",
        "    <p> 위의 사항을 코드로 구현하고, autograd를 통하여 구해진 x의 gradient와 위에서 계산해 낸 gradient가 일치하는지 확인하라.</p>\n",
        "</div>"
      ],
      "id": "98791695-0c59-40c8-aeb0-dd33e1a036a4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7098b1e6-e506-46e8-9eda-bb5828df7906",
        "outputId": "c1b9a112-0f90-4256-c5fa-81074c88c6f5"
      },
      "source": [
        "x = torch.ones(1, requires_grad=True)\n",
        "y = x * 2\n",
        "print(f'before backward 👉 x : {x}\\ty:{y}')\n",
        "\n",
        "y.backward()\n",
        "print(f'after  backward 👉 x : {x}\\ty:{y}')\n",
        "print(f'after  backward 👉 x.grad : {x.grad}')"
      ],
      "id": "7098b1e6-e506-46e8-9eda-bb5828df7906",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before backward 👉 x : tensor([1.], requires_grad=True)\ty:tensor([2.], grad_fn=<MulBackward0>)\n",
            "after  backward 👉 x : tensor([1.], requires_grad=True)\ty:tensor([2.], grad_fn=<MulBackward0>)\n",
            "after  backward 👉 x.grad : tensor([2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "605b329f-3000-4b15-8f03-837fa891cbac"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h4>Q3-1</h4>\n",
        "    <p> 아래과 같은 computational graph가 주어졌을 때, 주어진 질문에 답하여라. (문제출처 : cs231n. Lec 4)</p>\n",
        "    <img src=\"https://i.ibb.co/BnjksM2/p-3.png\" alt=\"q3\" border=\"1\">\n",
        "    <div>\n",
        "        👉 y = f/z - x<br>\n",
        "        👉 q = f/z = y + x<br>\n",
        "        👉 δf/δf = 1<br>\n",
        "        👉 δf/δq = z<br>\n",
        "        👉 δf/δx = z = -4<br>\n",
        "        👉 δf/δy = -4<br>\n",
        "        👉 δf/δz = 3<br>\n",
        "    </div>\n",
        "</div>"
      ],
      "id": "605b329f-3000-4b15-8f03-837fa891cbac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65ccd1e9-0068-40bc-be0f-95b024e50c4b"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h4>Q3-2</h4>\n",
        "    <p> 위의 사항을 코드로 구현하고, autograd를 통하여 구해진 x의 gradient와 위에서 계산해 낸 gradient가 일치하는지 확인하라.</p>\n",
        "</div>"
      ],
      "id": "65ccd1e9-0068-40bc-be0f-95b024e50c4b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b9e44ba-e90b-4fd7-ac6f-3f7158137556",
        "outputId": "35edf192-26f9-4b25-dabd-c8fbb93f52bf"
      },
      "source": [
        "x = torch.tensor([-2.0], requires_grad=True)\n",
        "y = torch.tensor([5.0], requires_grad=True)\n",
        "z = torch.tensor([-4.0], requires_grad=True)\n",
        "\n",
        "q = x + y\n",
        "f = q * z\n",
        "\n",
        "q.retain_grad()\n",
        "f.retain_grad()\n",
        "\n",
        "print(f'before backward 👉')\n",
        "print(f'  f : {f}')\n",
        "print(f'  q : {q}')\n",
        "print(f'  x : {x}')\n",
        "print(f'  y : {y}')\n",
        "print(f'  z : {z}')\n",
        "\n",
        "f.backward()\n",
        "print(f'after  backward 👉')\n",
        "print(f'  f : {f.grad}')\n",
        "print(f'  q : {q.grad}')\n",
        "print(f'  x : {x.grad}')\n",
        "print(f'  y : {y.grad}')\n",
        "print(f'  z : {z.grad}')"
      ],
      "id": "6b9e44ba-e90b-4fd7-ac6f-3f7158137556",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before backward 👉\n",
            "  f : tensor([-12.], grad_fn=<MulBackward0>)\n",
            "  q : tensor([3.], grad_fn=<AddBackward0>)\n",
            "  x : tensor([-2.], requires_grad=True)\n",
            "  y : tensor([5.], requires_grad=True)\n",
            "  z : tensor([-4.], requires_grad=True)\n",
            "after  backward 👉\n",
            "  f : tensor([1.])\n",
            "  q : tensor([-4.])\n",
            "  x : tensor([-4.])\n",
            "  y : tensor([-4.])\n",
            "  z : tensor([3.])\n"
          ]
        }
      ]
    }
  ]
}